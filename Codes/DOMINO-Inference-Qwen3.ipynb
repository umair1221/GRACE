{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55665a45",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9010d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share_2/users/umair_nawaz/.conda/envs/qwen3-vl/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/share_2/users/umair_nawaz/.conda/envs/qwen3-vl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- imports\n",
    "import os, re, json, glob, copy\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "# from transformers import AutoProcessor, Qwen3VLMoeForConditionalGeneration\n",
    "from transformers import AutoModelForImageTextToText, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# --- small utils\n",
    "def to_file_url(p: str) -> str:\n",
    "    if p.startswith((\"http://\", \"https://\", \"file://\")):\n",
    "        return p\n",
    "    ap = os.path.abspath(p)\n",
    "    if not os.path.exists(ap):\n",
    "        raise FileNotFoundError(f\"Missing image: {p}\")\n",
    "    return \"file://\" + ap.replace(\"\\\\\", \"/\")\n",
    "\n",
    "def extract_json(text: str) -> Dict[str, Any]:\n",
    "    m = re.search(r'\\{.*\\}', text, flags=re.S)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in model output.\")\n",
    "    s = m.group(0)\n",
    "    s = re.sub(r'<\\|.*?\\|>', '', s)\n",
    "    s = s.replace('\\n', ' ')\n",
    "    return json.loads(s)\n",
    "\n",
    "def natural_key(s: str):\n",
    "    base = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', base)]\n",
    "\n",
    "# --- draw overlays (solid red outlines; very visible)\n",
    "def draw_and_save(image_path: str,\n",
    "                  boxes_xyxy_px: List[Tuple[int,int,int,int]],\n",
    "                  labels: List[str],\n",
    "                  out_path: str,\n",
    "                  outline_width: int = 5):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    d = ImageDraw.Draw(img)\n",
    "    labels = labels or [f\"box{i+1}\" for i in range(len(boxes_xyxy_px))]\n",
    "\n",
    "    for (x1, y1, x2, y2), lab in zip(boxes_xyxy_px, labels):\n",
    "\n",
    "        # abs_y1 = int(y1/999 * img.size[1])\n",
    "        # abs_x1 = int(x1/999 * img.size[0])\n",
    "        # abs_y2 = int(y2/999 * img.size[1])\n",
    "        # abs_x2 = int(x2/999 * img.size[0])\n",
    "        d.rectangle([x1, y1, x2, y2], outline=(255,0,0), width=outline_width)\n",
    "        # label chip\n",
    "        try:\n",
    "            l,t,r,b = d.textbbox((0,0), lab)\n",
    "            tw, th = r-l, b-t\n",
    "        except Exception:\n",
    "            tw, th = max(8*len(lab), 16), 16\n",
    "        pad = 4\n",
    "        chip = [x1, max(0, y1 - th - 2*pad), x1 + tw + 2*pad, y1]\n",
    "        d.rectangle(chip, fill=(255,0,0))\n",
    "        d.text((chip[0]+pad, chip[1]+pad), lab, fill=(255,255,255))\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    img.save(out_path, quality=95)\n",
    "\n",
    "# --- convert res[\"json\"] -> pixel xyxy; robust to mislabeled formats\n",
    "def boxes_px_from_res_json(res_json: dict, image_path: str):\n",
    "    W, H = Image.open(image_path).size\n",
    "    fmt = (res_json.get(\"box_format\") or \"\").lower()\n",
    "    out_boxes, out_labels = [], []\n",
    "\n",
    "    # def clamp_box(x1, y1, x2, y2):\n",
    "    #     x1 = max(0, min(W-1, int(round(x1))))\n",
    "    #     y1 = max(0, min(H-1, int(round(y1))))\n",
    "    #     x2 = max(0, min(W-1, int(round(x2))))\n",
    "    #     y2 = max(0, min(H-1, int(round(y2))))\n",
    "    #     if x2 <= x1: x2 = min(W-1, x1 + 2)\n",
    "    #     if y2 <= y1: y2 = min(H-1, y1 + 2)\n",
    "    #     return (x1, y1, x2, y2)\n",
    "\n",
    "    for item in res_json.get(\"click_boxes\", []):\n",
    "        lab = item.get(\"label\", \"box\")\n",
    "        box = item.get(\"box\", [])\n",
    "\n",
    "        \n",
    "        abs_x1 = int(box[0]/999 * W)\n",
    "        abs_y1 = int(box[1]/999 * H)\n",
    "        abs_x2 = int(box[2]/999 * W)\n",
    "        abs_y2 = int(box[3]/999 * H)\n",
    "\n",
    "        box = [abs_x1, abs_y1, abs_x2, abs_y2]\n",
    "\n",
    "\n",
    "        if not (isinstance(box, (list, tuple)) and len(box) == 4):\n",
    "            continue\n",
    "        x1, y1, x2, y2 = [float(v) for v in box]\n",
    "\n",
    "        # if fmt in (\"xyxy_norm\", \"x1y1x2y2_norm\"):\n",
    "        #     if max(x1, y1, x2, y2) <= 1.5:  # looks normalized\n",
    "        #         X1, Y1, X2, Y2 = x1*W, y1*H, x2*W, y2*H\n",
    "        #     else:                           # mislabeled; already pixels\n",
    "        #         X1, Y1, X2, Y2 = x1, y1, x2, y2\n",
    "        # elif fmt in (\"xywh_norm\",):\n",
    "        #     if max(x1, y1, x2, y2) <= 1.5:\n",
    "        #         X1, Y1, X2, Y2 = x1*W, y1*H, (x1+x2)*W, (y1+y2)*H\n",
    "        #     else:\n",
    "        #         X1, Y1, X2, Y2 = x1, y1, x1+x2, y1+y2\n",
    "        # elif fmt in (\"xywh\",):\n",
    "        #     X1, Y1, X2, Y2 = x1, y1, x1+x2, y1+y2\n",
    "        # else:  # xyxy/unknown → assume pixels\n",
    "        #     X1, Y1, X2, Y2 = x1, y1, x2, y2\n",
    "\n",
    "        out_boxes.append((abs_x1, abs_y1, abs_x2, abs_y2))\n",
    "        out_labels.append(lab)\n",
    "\n",
    "    return out_boxes, out_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8d9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_task_meta(task_dir: str):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      task_query: str\n",
    "      instr_by_file: dict like {\"1.png\": \"Open the View tab\", ...}\n",
    "    \"\"\"\n",
    "    annot = os.path.join(task_dir, \"annotations.json\")\n",
    "    task_query = os.path.basename(task_dir)\n",
    "    instr_by_file = {}\n",
    "\n",
    "    if os.path.exists(annot):\n",
    "        with open(annot, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        task_query = data.get(\"task_query\") or data.get(\"task_name\") or task_query\n",
    "        for im in data.get(\"images\", []):\n",
    "            fname = im.get(\"file_name\")\n",
    "            instr = im.get(\"instruction\") or \"\"\n",
    "            if fname:\n",
    "                instr_by_file[fname] = instr\n",
    "    return task_query, instr_by_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f7b5551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_messages_for_image(image_path: str, task_query: str, image_instruction: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    We pass BOTH:\n",
    "      - the global task (task_query), and\n",
    "      - the per-image instruction (image_instruction).\n",
    "    We also ask the model to set label==instruction, though we will enforce it downstream anyway.\n",
    "    \"\"\"\n",
    "    sys_txt = (\n",
    "        \"You are a precise UI grounding assistant. \"\n",
    "        \"Given a GUI screenshot, a global task, and the step instruction for THIS image, \"\n",
    "        \"output STRICT JSON only with bounding boxes needed on THIS screen. \"\n",
    "        \"Use normalized coordinates (xyxy_norm) in [0,1] relative to this image. \"\n",
    "        \"Set each box's 'label' EXACTLY to the provided instruction.\"\n",
    "    )\n",
    "    system = {\"role\": \"system\", \"content\": [{\"type\": \"text\", \"text\": sys_txt}]}\n",
    "\n",
    "    schema = (\n",
    "        \"{\\n\"\n",
    "        '  \"image\": \"<filename>\",\\n'\n",
    "        '  \"box_format\": \"xyxy_norm\",\\n'\n",
    "        '  \"click_boxes\": [\\n'\n",
    "        '     {\"label\": \"<instruction>\", \"box\": [x1,y1,x2,y2]},\\n'\n",
    "        \"     ...\\n\"\n",
    "        \"  ]\\n\"\n",
    "        \"}\\n\"\n",
    "        \"Only valid JSON. Coordinates 0..1. If no action is needed on this screen, return an empty list.\"\n",
    "    )\n",
    "\n",
    "    user_content = [\n",
    "        {\"type\": \"text\", \"text\": f\"Global task: {task_query}\"},\n",
    "        {\"type\": \"text\", \"text\": f\"Instruction for this image: {image_instruction}\"},\n",
    "        {\"type\": \"text\", \"text\": f\"Image filename: {os.path.basename(image_path)}\"},\n",
    "        {\"type\": \"image\", \"image\": to_file_url(image_path)},\n",
    "        {\"type\": \"text\", \"text\": \"Return JSON with this schema:\"},\n",
    "        {\"type\": \"text\", \"text\": schema},\n",
    "    ]\n",
    "    return [{\"role\": \"user\", \"content\": user_content}, system]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26408ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def infer_one(model, processor, image_path: str, task_query: str, image_instruction: str,\n",
    "              temperature: float = 0.0, max_new_tokens: int = 256):\n",
    "    messages = build_messages_for_image(image_path, task_query, image_instruction)\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    images, videos, vkw = process_vision_info(messages, return_video_kwargs=True)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=images, videos=videos,\n",
    "        return_tensors=\"pt\", padding=True, **(vkw or {})\n",
    "    )\n",
    "    for k, v in list(inputs.items()):\n",
    "        if hasattr(v, \"to\"):\n",
    "            inputs[k] = v.to(model.device)\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "\n",
    "    out = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    new_tokens = [o[len(i):] for i, o in zip(inputs[\"input_ids\"], out)]\n",
    "    txt = processor.batch_decode(new_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "\n",
    "    # print(\"Results of model are: \", txt, \"\\n\\n\")\n",
    "\n",
    "    # parse model JSON\n",
    "    try:\n",
    "        parsed = extract_json(txt)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] JSON parse failed for {os.path.basename(image_path)}: {e}\\nRAW[:400]: {txt[:400]}\")\n",
    "        parsed = {\"image\": os.path.basename(image_path), \"box_format\": \"xyxy_norm\", \"click_boxes\": []}\n",
    "\n",
    "    # convert to pixel xyxy\n",
    "    boxes_px, _labels_from_model = boxes_px_from_res_json(parsed, image_path)\n",
    "\n",
    "    # IMPORTANT: override labels with the per-image instruction (your requirement)\n",
    "    labels = [image_instruction] * len(boxes_px)\n",
    "\n",
    "    # also write a copy of the prediction with labels overwritten, for evaluation convenience\n",
    "    # pred_with_instruction = copy.deepcopy(parsed)\n",
    "    # for cb in pred_with_instruction.get(\"click_boxes\", []):\n",
    "    #     cb[\"label\"] = image_instruction\n",
    "\n",
    "    pred_with_instruction, changed = enforce_instruction_label(parsed, image_instruction)\n",
    "\n",
    "    W, H = Image.open(image_path).size\n",
    "    return {\n",
    "        \"raw_text\": txt,\n",
    "        \"prediction_raw\": parsed,                   # keep raw internally; caller can drop it\n",
    "        \"prediction\": pred_with_instruction,        # labels set to the instruction\n",
    "        \"label_overridden\": bool(changed),\n",
    "        \"boxes_px\": boxes_px,                       # (computed however you prefer)\n",
    "        \"labels\": [image_instruction] * len(boxes_px),\n",
    "        \"image_size\": (W, H),\n",
    "    }\n",
    "import copy\n",
    "\n",
    "def enforce_instruction_label(parsed_json: dict, instruction: str):\n",
    "    \"\"\"\n",
    "    Returns (pred_with_instruction, changed: bool)\n",
    "    - Sets each click_boxes[i][\"label\"] = instruction\n",
    "    - `changed` is True if any original label differed\n",
    "    \"\"\"\n",
    "    pj = copy.deepcopy(parsed_json)\n",
    "    changed = False\n",
    "    for cb in pj.get(\"click_boxes\", []):\n",
    "        if cb.get(\"label\") != instruction:\n",
    "            changed = True\n",
    "        cb[\"label\"] = instruction\n",
    "    return pj, changed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33a3fa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 14/14 [00:24<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready on: cuda:0\n",
      "Predictions root: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL\n"
     ]
    }
   ],
   "source": [
    "# Top-level directory that contains: Predictions/, Task-1/, Task-2/, ...\n",
    "# import necessary libraries\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "ROOT_DIR   = \"/share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS\"  # folder that contains Task-1, Task-2, ...\n",
    "MODEL_ID = \"Qwen/Qwen3-VL-32B-Instruct\"  # or 7B/14B if you have access\n",
    "# MODEL_ID = \"Qwen/Qwen2.5-VL-32B-Instruct\"\n",
    "# MODEL_ID = \"Qwen/Qwen2-VL-7B\"  # or 7B/14B if you have access\n",
    "PRED_ROOT  = os.path.join(ROOT_DIR, \"Predictions-Qwen3-32B-VL\")  # <-- all outputs go here\n",
    "FILE_EXTS  = (\".png\", \".jpg\", \".jpeg\", \".PNG\", \".JPG\", \".JPEG\")\n",
    "TEMP       = 0.0\n",
    "MAXTOK     = 256\n",
    "\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.bfloat16\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    MODEL_ID, torch_dtype=torch_dtype, device_map=\"cuda\", attn_implementation=\"sdpa\"\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "os.makedirs(PRED_ROOT, exist_ok=True)\n",
    "print(\"Model ready on:\", model.device)\n",
    "print(\"Predictions root:\", PRED_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6475cbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 task(s).\n",
      "\n",
      "=== 1 :: Sort by newest study and expand first row ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/1/predictions.jsonl\n",
      "\n",
      "=== 2 :: Sort by Patient Name then inspect a row ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/2/predictions.jsonl\n",
      "\n",
      "=== 3 :: Sort by Description and preview a different row ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/3/predictions.jsonl\n",
      "\n",
      "=== 4 :: Sort by Accession # and expand a CT row ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/4/predictions.jsonl\n",
      "\n",
      "=== 5 :: Filter modality to CT using dropdown ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/5/predictions.jsonl\n",
      "\n",
      "=== 6 :: Filter modality to MR using dropdown ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/6/predictions.jsonl\n",
      "\n",
      "=== 7 :: Apply a start date filter with the date picker ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 0)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/7/predictions.jsonl\n",
      "\n",
      "=== 8 :: Apply an end date filter with the date picker ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/8/predictions.jsonl\n",
      "\n",
      "=== 9 :: Set both start and end date ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 0)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/9/predictions.jsonl\n",
      "\n",
      "=== 10 :: Inspect three specific rows sequentially ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/10/predictions.jsonl\n",
      "\n",
      "=== 11 :: Load MR/CR/CT/DR into the 2×2 layout ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "  7.png -> 7_pred.png (boxes: 1)\n",
      "  8.png -> 8_pred.png (boxes: 1)\n",
      "  9.png -> 9_pred.png (boxes: 1)\n",
      "  10.png -> 10_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/11/predictions.jsonl\n",
      "\n",
      "=== 12 :: Replace the top-right viewport with a different CR series ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/12/predictions.jsonl\n",
      "\n",
      "=== 13 :: Save a screenshot of the active viewport ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/13/predictions.jsonl\n",
      "\n",
      "=== 14 :: Reset the bottom-right viewport view ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/14/predictions.jsonl\n",
      "\n",
      "=== 15 :: Rotate the bottom-left viewport 90° right and then reset ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/15/predictions.jsonl\n",
      "\n",
      "=== 16 :: Zoom then return to window/level tool ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/16/predictions.jsonl\n",
      "\n",
      "=== 17 :: Add an empty segmentation and select the brush tool ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/17/predictions.jsonl\n",
      "\n",
      "=== 18 :: Play cine on the long series (120) in top-right ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/18/predictions.jsonl\n",
      "\n",
      "=== 19 :: Increase FPS  with cine controls ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/19/predictions.jsonl\n",
      "\n",
      "=== 20 :: Reset each viewport view sequentially ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "  7.png -> 7_pred.png (boxes: 1)\n",
      "  8.png -> 8_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/20/predictions.jsonl\n",
      "\n",
      "=== 21 :: Compare two SPECT series in 1×2 layout ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/21/predictions.jsonl\n",
      "\n",
      "=== 22 :: Compare CTAC vs CT Std in 1×2 ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/22/predictions.jsonl\n",
      "\n",
      "=== 23 :: Load CT Std into all four viewports ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "  7.png -> 7_pred.png (boxes: 1)\n",
      "  8.png -> 8_pred.png (boxes: 1)\n",
      "  9.png -> 9_pred.png (boxes: 1)\n",
      "  10.png -> 10_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/23/predictions.jsonl\n",
      "\n",
      "=== 24 :: Apply Lung preset to the left CT ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/24/predictions.jsonl\n",
      "\n",
      "=== 25 :: Apply Default preset to the right CT ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/25/predictions.jsonl\n",
      "\n",
      "=== 26 :: Link CTAC and CT Std ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 2)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/26/predictions.jsonl\n",
      "\n",
      "=== 27 :: Invert CT image and reset ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/27/predictions.jsonl\n",
      "\n",
      "=== 28 :: Focus “Brain Stem” and hide BODY & Brain ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 2)\n",
      "  4.png -> 4_pred.png (boxes: 2)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/28/predictions.jsonl\n",
      "\n",
      "=== 29 :: Temporarily hide both lenses ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/29/predictions.jsonl\n",
      "\n",
      "=== 30 :: Add a new empty segment and select Brush ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 3)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/30/predictions.jsonl\n",
      "\n",
      "=== 31 :: Show only GTV1 (by toggling its visibility) ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/31/predictions.jsonl\n",
      "\n",
      "=== 32 :: Save a screenshot of the current view ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/32/predictions.jsonl\n",
      "\n",
      "=== 33 :: Invert image and then reset view ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/33/predictions.jsonl\n",
      "\n",
      "=== 34 :: Apply Brain window/level preset ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/34/predictions.jsonl\n",
      "\n",
      "=== 35 :: Collapse and re-expand the segment list ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/35/predictions.jsonl\n",
      "\n",
      "=== 36 :: Load 2.0, Body 3.0 CE, Lung 3.0 CE, Body 4.0 CE into 2×2 ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "  7.png -> 7_pred.png (boxes: 1)\n",
      "  8.png -> 8_pred.png (boxes: 1)\n",
      "  9.png -> 9_pred.png (boxes: 1)\n",
      "  10.png -> 10_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/36/predictions.jsonl\n",
      "\n",
      "=== 37 :: Compare Body 3.0 CE vs Lung 3.0 CE in 1×2 ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/37/predictions.jsonl\n",
      "\n",
      "=== 38 :: Apply soft-tissue WW/WL to Body 3.0 CE and Lung preset to Lung 3.0 CE ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "  7.png -> 7_pred.png (boxes: 1)\n",
      "  8.png -> 8_pred.png (boxes: 1)\n",
      "  9.png -> 9_pred.png (boxes: 1)\n",
      "  10.png -> 10_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/38/predictions.jsonl\n",
      "\n",
      "=== 39 :: Save a screenshot of the top-right (Body 3.0 CE) viewport ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/39/predictions.jsonl\n",
      "\n",
      "=== 40 :: Invert the bottom-right Body 4.0 CE image and reset ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 2)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/40/predictions.jsonl\n",
      "\n",
      "=== 41 :: Start a blank segmentation and pick Brush on top-left ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/41/predictions.jsonl\n",
      "\n",
      "=== 42 :: Collapse and re-expand the Segmentation side panel ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/42/predictions.jsonl\n",
      "\n",
      "=== 43 :: Collapse and re-expand the Studies/Series side panel ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/43/predictions.jsonl\n",
      "\n",
      "=== 44 :: Set top-right cine speed to 8 FPS (exact) ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/44/predictions.jsonl\n",
      "\n",
      "=== 45 :: Jump frames in top-right using the vertical stack scrollbar ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/45/predictions.jsonl\n",
      "\n",
      "=== 46 :: Use Magnify tool briefly, then exit ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 2)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/46/predictions.jsonl\n",
      "\n",
      "=== 47 :: Switch to Zoom tool, then back to Window/Level ===\n",
      "  1.png -> 1_pred.png (boxes: 2)\n",
      "  2.png -> 2_pred.png (boxes: 2)\n",
      "  3.png -> 3_pred.png (boxes: 3)\n",
      "  4.png -> 4_pred.png (boxes: 2)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/47/predictions.jsonl\n",
      "\n",
      "=== 48 :: Make viewports active clockwise ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/48/predictions.jsonl\n",
      "\n",
      "=== 49 :: Load the 166-frame US series into the bottom-right viewport ===\n",
      "  1.png -> 1_pred.png (boxes: 1)\n",
      "  2.png -> 2_pred.png (boxes: 1)\n",
      "  3.png -> 3_pred.png (boxes: 1)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/49/predictions.jsonl\n",
      "\n",
      "=== 50 :: Normalize cine speed to 8 FPS in all viewports ===\n",
      "  1.png -> 1_pred.png (boxes: 2)\n",
      "  2.png -> 2_pred.png (boxes: 3)\n",
      "  3.png -> 3_pred.png (boxes: 2)\n",
      "  4.png -> 4_pred.png (boxes: 1)\n",
      "  5.png -> 5_pred.png (boxes: 2)\n",
      "  6.png -> 6_pred.png (boxes: 1)\n",
      "  7.png -> 7_pred.png (boxes: 2)\n",
      "  8.png -> 8_pred.png (boxes: 1)\n",
      "Saved: /share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS/Predictions-Qwen3-32B-VL/50/predictions.jsonl\n"
     ]
    }
   ],
   "source": [
    "def is_task_dir(path: str) -> bool:\n",
    "    if not os.path.isdir(path):\n",
    "        return False\n",
    "    if os.path.basename(path).lower() == \"predictions-qwen3-8b-vl\":\n",
    "        return False\n",
    "    for ext in FILE_EXTS:\n",
    "        if glob.glob(os.path.join(path, f\"*{ext}\")):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def list_task_dirs(root_dir: str) -> List[str]:\n",
    "    return [\n",
    "        os.path.join(root_dir, name)\n",
    "        for name in sorted(os.listdir(root_dir), key=natural_key)\n",
    "        if is_task_dir(os.path.join(root_dir, name))\n",
    "    ]\n",
    "\n",
    "def run_all_tasks(root_dir: str, pred_root: str, out_img_suffix=\"_pred.png\"):\n",
    "    task_dirs = list_task_dirs(root_dir)\n",
    "    print(f\"Found {len(task_dirs)} task(s).\")\n",
    "\n",
    "    # (optional) aggregate across tasks\n",
    "    agg_path = os.path.join(pred_root, \"all_predictions.jsonl\")\n",
    "    with open(agg_path, \"w\", encoding=\"utf-8\") as _:\n",
    "        pass\n",
    "\n",
    "    for task_dir in task_dirs:\n",
    "        task_label = os.path.basename(task_dir)\n",
    "        task_query, instr_by_file = load_task_meta(task_dir)\n",
    "\n",
    "        out_task_dir = os.path.join(pred_root, task_label)\n",
    "        os.makedirs(out_task_dir, exist_ok=True)\n",
    "        pred_jsonl_path = os.path.join(out_task_dir, \"predictions.jsonl\")\n",
    "\n",
    "        # collect images for this task\n",
    "        image_paths = []\n",
    "        for ext in FILE_EXTS:\n",
    "            image_paths += glob.glob(os.path.join(task_dir, f\"*{ext}\"))\n",
    "        image_paths = sorted(set(image_paths), key=natural_key)\n",
    "\n",
    "        print(f\"\\n=== {task_label} :: {task_query} ===\")\n",
    "        with open(pred_jsonl_path, \"w\", encoding=\"utf-8\") as f_out, \\\n",
    "             open(os.path.join(pred_root, \"all_predictions.jsonl\"), \"a\", encoding=\"utf-8\") as agg_out:\n",
    "            for img_path in image_paths:\n",
    "                fname = os.path.basename(img_path)\n",
    "                instruction = instr_by_file.get(fname, \"\")  # may be empty if not in annotations.json\n",
    "\n",
    "                # --- inference using per-image instruction\n",
    "                res = infer_one(\n",
    "                    model, processor,\n",
    "                    image_path=img_path,\n",
    "                    task_query=task_query,\n",
    "                    image_instruction=instruction,\n",
    "                    temperature=TEMP, max_new_tokens=MAXTOK,\n",
    "                )\n",
    "                \n",
    "\n",
    "                # # --- draw with labels = instruction\n",
    "                # boxes_px, labels = boxes_px_from_res_json(res[\"prediction_with_instruction\"], img_path)\n",
    "                # overlay_path = os.path.join(out_task_dir, f\"{os.path.splitext(fname)[0]}{out_img_suffix}\")\n",
    "                # draw_and_save(img_path, boxes_px, labels, overlay_path)\n",
    "\n",
    "                # Enforce the label again on what we write (defensive; cheap)\n",
    "                pred_with_instruction, changed = enforce_instruction_label(res[\"prediction_raw\"], instruction)\n",
    "\n",
    "                # If you derive boxes from JSON, do it from pred_with_instruction:\n",
    "                boxes_px, labels = boxes_px_from_res_json(pred_with_instruction, img_path)\n",
    "\n",
    "\n",
    "                # --- write JSON line (store both model raw + overridden labels)\n",
    "                record = {\n",
    "                    \"task\": task_label,\n",
    "                    \"task_query\": task_query,\n",
    "                    \"image\": fname,\n",
    "                    \"instruction\": instruction,                 # <-- the label we want on disk\n",
    "                    \"image_relpath\": os.path.relpath(img_path, root_dir),\n",
    "                    \"image_size\": res[\"image_size\"],\n",
    "                    \"prediction\": pred_with_instruction,        # <-- labels == instruction\n",
    "                    \"boxes_px\": boxes_px,\n",
    "                    \"labels\": labels,                            # == instruction repeated\n",
    "                    \"label_overridden\": bool(changed),\n",
    "                }\n",
    "\n",
    "                # Only attach raw when it differs (changed=True)\n",
    "                if changed:\n",
    "                    record[\"prediction_raw\"] = res[\"prediction_raw\"]\n",
    "\n",
    "                # save overlay using enforced labels\n",
    "                overlay_path = os.path.join(out_task_dir, f\"{os.path.splitext(fname)[0]}{out_img_suffix}\")\n",
    "                draw_and_save(img_path, boxes_px, labels, overlay_path)\n",
    "\n",
    "                \n",
    "                # write the line\n",
    "                line = json.dumps(record, ensure_ascii=False)\n",
    "                f_out.write(line + \"\\n\")\n",
    "                agg_out.write(line + \"\\n\")\n",
    "\n",
    "                print(f\"  {fname} -> {os.path.relpath(overlay_path, out_task_dir)} \"\n",
    "                      f\"(boxes: {len(boxes_px)})\")\n",
    "\n",
    "        print(f\"Saved: {pred_jsonl_path}\")\n",
    "\n",
    "# go!\n",
    "run_all_tasks(ROOT_DIR, PRED_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62572f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e8014a",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574435df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a837e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Root that contains Predictions/ and Task-* folders\n",
    "ROOT_DIR  = \"/share_2/users/umair_nawaz/DOMINO-Evaluation/Medical/OHIF/SS\"\n",
    "PRED_DIR  = os.path.join(ROOT_DIR, \"Predictions-Qwen3-32B-VL\")\n",
    "\n",
    "# IoU thresholds (you can change these)\n",
    "THRESHOLDS = [0.3, 0.5, 0.75, 0.9]\n",
    "PRIMARY_TAU = 0.3   # for Task Completion@τ\n",
    "\n",
    "# Require predicted label to equal the per-image instruction?\n",
    "# (Your pipeline already enforces this, so keep True. Set False to ignore label text.)\n",
    "REQUIRE_LABEL_MATCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70ec1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, glob\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from pathlib import Path\n",
    "\n",
    "def xywh_to_xyxy(b: List[float]) -> Tuple[float,float,float,float]:\n",
    "    x, y, w, h = b\n",
    "    return (x, y, x + w, y + h)\n",
    "\n",
    "def iou_xyxy(a: Tuple[float,float,float,float],\n",
    "             b: Tuple[float,float,float,float]) -> float:\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    inter_w = max(0.0, min(ax2, bx2) - max(ax1, bx1))\n",
    "    inter_h = max(0.0, min(ay2, by2) - max(ay1, by1))\n",
    "    inter   = inter_w * inter_h\n",
    "    area_a  = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)\n",
    "    area_b  = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)\n",
    "    denom   = area_a + area_b - inter\n",
    "    return (inter / denom) if denom > 0 else 0.0\n",
    "\n",
    "def load_annotations(task_dir: str) -> Dict[str, Any]:\n",
    "    \"\"\"Return GT-by-image: {file_name: {boxes:[xyxy...], instruction:str, size:(W,H)}}\"\"\"\n",
    "    annot_path = os.path.join(task_dir, \"annotations.json\")\n",
    "    with open(annot_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    by_img = {}\n",
    "    for im in data.get(\"images\", []):\n",
    "        W, H = im[\"width\"], im[\"height\"]\n",
    "        boxes = [xywh_to_xyxy(bb[\"bbox\"]) for bb in im.get(\"bboxes\", [])]\n",
    "        by_img[im[\"file_name\"]] = {\n",
    "            \"boxes\": boxes,\n",
    "            \"instruction\": im.get(\"instruction\", \"\"),\n",
    "            \"size\": (W, H),\n",
    "            \"step_index\": im.get(\"step_index\"),\n",
    "        }\n",
    "    task_query = data.get(\"task_query\") or data.get(\"task_name\") or os.path.basename(task_dir)\n",
    "    return {\"task_query\": task_query, \"by_image\": by_img}\n",
    "\n",
    "def boxes_px_from_prediction_record(rec: Dict[str, Any], root_dir: str, task_name: str) -> Tuple[List[Tuple[int,int,int,int]], List[str], Tuple[int,int]]:\n",
    "    \"\"\"\n",
    "    Pull predicted boxes (pixel xyxy) + labels from a predictions.jsonl record.\n",
    "    Prefers boxes_px; otherwise converts from prediction.box_format.\n",
    "    Returns: (boxes_px, labels, image_size)\n",
    "    \"\"\"\n",
    "    # Fast path\n",
    "    if \"boxes_px\" in rec and isinstance(rec[\"boxes_px\"], list) and len(rec[\"boxes_px\"]) > 0:\n",
    "        boxes = [tuple(map(int, b)) for b in rec[\"boxes_px\"]]\n",
    "        labels = rec.get(\"labels\", [])\n",
    "        size = tuple(rec.get(\"image_size\", (0, 0)))\n",
    "        return boxes, labels, size\n",
    "\n",
    "    # Convert from normalized/other formats\n",
    "    pred = rec.get(\"prediction\") or rec.get(\"prediction_raw\") or {}\n",
    "    box_format = (pred.get(\"box_format\") or \"\").lower()\n",
    "\n",
    "    # Determine size\n",
    "    size = tuple(rec.get(\"image_size\", (0, 0)))\n",
    "    if not (size and size[0] > 0 and size[1] > 0):\n",
    "        # fall back to reading the original image file if relpath is available\n",
    "        rel = rec.get(\"image_relpath\")\n",
    "        if rel:\n",
    "            try:\n",
    "                from PIL import Image\n",
    "                W, H = Image.open(os.path.join(root_dir, rel)).size\n",
    "                size = (W, H)\n",
    "            except Exception:\n",
    "                pass\n",
    "    W, H = size if (size and size[0] > 0 and size[1] > 0) else (1, 1)\n",
    "\n",
    "    boxes_px, labels = [], []\n",
    "    for item in pred.get(\"click_boxes\", []):\n",
    "        lab = item.get(\"label\", \"box\")\n",
    "        box = item.get(\"box\", [])\n",
    "        if not (isinstance(box, (list, tuple)) and len(box) == 4):\n",
    "            continue\n",
    "        x1, y1, x2, y2 = [float(v) for v in box]\n",
    "\n",
    "        if box_format in (\"xyxy_norm\", \"x1y1x2y2_norm\"):\n",
    "            if max(x1, y1, x2, y2) <= 1.5:  # likely normalized\n",
    "                X1, Y1, X2, Y2 = x1 * W, y1 * H, x2 * W, y2 * H\n",
    "            else:\n",
    "                X1, Y1, X2, Y2 = x1, y1, x2, y2\n",
    "        elif box_format in (\"xywh_norm\",):\n",
    "            if max(x1, y1, x2, y2) <= 1.5:\n",
    "                X1, Y1, X2, Y2 = x1 * W, y1 * H, (x1 + x2) * W, (y1 + y2) * H\n",
    "            else:\n",
    "                X1, Y1, X2, Y2 = x1, y1, x1 + x2, y1 + y2\n",
    "        elif box_format in (\"xywh\",):\n",
    "            X1, Y1, X2, Y2 = x1, y1, x1 + x2, y1 + y2\n",
    "        else:  # xyxy or unknown → assume pixels\n",
    "            X1, Y1, X2, Y2 = x1, y1, x2, y2\n",
    "\n",
    "        # clamp\n",
    "        X1 = max(0, min(int(round(X1)), W - 1))\n",
    "        Y1 = max(0, min(int(round(Y1)), H - 1))\n",
    "        X2 = max(0, min(int(round(X2)), W - 1))\n",
    "        Y2 = max(0, min(int(round(Y2)), H - 1))\n",
    "        if X2 <= X1: X2 = min(W - 1, X1 + 2)\n",
    "        if Y2 <= Y1: Y2 = min(H - 1, Y1 + 2)\n",
    "\n",
    "        boxes_px.append((X1, Y1, X2, Y2))\n",
    "        labels.append(lab)\n",
    "\n",
    "    return boxes_px, labels, (W, H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1e6440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_match_iou(gt_boxes: List[Tuple[float,float,float,float]],\n",
    "                     pred_boxes: List[Tuple[int,int,int,int]],\n",
    "                     label_ok: bool = True) -> List[Tuple[int,int,float]]:\n",
    "    \"\"\"\n",
    "    Return list of (gt_idx, pred_idx, IoU) with greedy, IoU-descending matching.\n",
    "    If label_ok=False, you could pass a parallel check; here we already enforce labels in records.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    for gi, gb in enumerate(gt_boxes):\n",
    "        for pi, pb in enumerate(pred_boxes):\n",
    "            pairs.append((gi, pi, iou_xyxy(gb, pb)))\n",
    "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    used_g, used_p, out = set(), set(), []\n",
    "    for gi, pi, i in pairs:\n",
    "        if gi in used_g or pi in used_p:\n",
    "            continue\n",
    "        used_g.add(gi); used_p.add(pi)\n",
    "        out.append((gi, pi, i))\n",
    "    return out\n",
    "\n",
    "def score_task(task_dir: str, pred_task_dir: str,\n",
    "               primary_tau: float = 0.25,\n",
    "               thresholds: List[float] = [0.25, 0.5, 0.75, 0.9],\n",
    "               require_label_match: bool = True) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compare Predictions/<Task-X>/Predictions-Qwen2-VL.jsonl with Task-X/annotations.json\n",
    "    \"\"\"\n",
    "    gt = load_annotations(task_dir)\n",
    "    task_query = gt[\"task_query\"]\n",
    "    gt_by_img = gt[\"by_image\"]\n",
    "\n",
    "    pred_file = os.path.join(pred_task_dir, \"predictions.jsonl\")\n",
    "    if not os.path.exists(pred_file):\n",
    "        return {\"task\": os.path.basename(task_dir), \"exists\": False, \"reason\": \"missing predictions.jsonl\"}\n",
    "\n",
    "    # load predictions\n",
    "    preds = []\n",
    "    with open(pred_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line: continue\n",
    "            preds.append(json.loads(line))\n",
    "\n",
    "    preds_by_img = {p[\"image\"]: p for p in preds}\n",
    "\n",
    "    per_image_rows = []\n",
    "    total_gt_boxes = 0\n",
    "    iou_list_best_per_gt = []  # one value per GT box (best matched IoU; 0 if none)\n",
    "\n",
    "    step_pass = {}  # fname -> bool at primary_tau\n",
    "\n",
    "    for fname, meta in gt_by_img.items():\n",
    "        gt_boxes = meta[\"boxes\"]\n",
    "        total_gt_boxes += len(gt_boxes)\n",
    "        instruction = meta.get(\"instruction\", \"\")\n",
    "        # fetch prediction record for this image\n",
    "        prec = preds_by_img.get(fname)\n",
    "        if not prec:\n",
    "            # no prediction => zeros\n",
    "            best_iou = 0.0\n",
    "            ious_for_gts = [0.0] * len(gt_boxes)\n",
    "            per_image_rows.append({\n",
    "                \"image\": fname, \"instruction\": instruction,\n",
    "                \"best_iou\": 0.0, \"gt_count\": len(gt_boxes),\n",
    "                \"matched\": 0, \"note\": \"no_prediction\"\n",
    "            })\n",
    "            iou_list_best_per_gt.extend(ious_for_gts)\n",
    "            step_pass[fname] = False\n",
    "            continue\n",
    "\n",
    "        # collect predicted boxes (pixels) + labels\n",
    "        pred_boxes, pred_labels, _sz = boxes_px_from_prediction_record(prec, ROOT_DIR, os.path.basename(task_dir))\n",
    "\n",
    "        # optionally filter preds whose label != instruction\n",
    "        if require_label_match:\n",
    "            pred_keep = [i for i, lab in enumerate(pred_labels) if str(lab).strip() == str(instruction).strip()]\n",
    "            pred_boxes = [pred_boxes[i] for i in pred_keep]\n",
    "            pred_labels = [pred_labels[i] for i in pred_keep]\n",
    "\n",
    "        # match\n",
    "        matches = greedy_match_iou(gt_boxes, pred_boxes)\n",
    "        matched_iou = [0.0] * len(gt_boxes)\n",
    "        for gi, pi, i in matches:\n",
    "            matched_iou[gi] = max(matched_iou[gi], i)\n",
    "\n",
    "        # step success = every GT box on this image matched at >= primary_tau\n",
    "        step_success = all(i >= primary_tau for i in matched_iou) if len(gt_boxes) > 0 else True\n",
    "        step_pass[fname] = step_success\n",
    "\n",
    "        # per-image logging\n",
    "        per_image_rows.append({\n",
    "            \"image\": fname,\n",
    "            \"instruction\": instruction,\n",
    "            \"gt_count\": len(gt_boxes),\n",
    "            \"pred_count\": len(pred_boxes),\n",
    "            \"best_iou\": max(matched_iou) if matched_iou else 0.0,\n",
    "            \"ious_per_gt\": matched_iou,\n",
    "            \"step_success@{:.3f}\".format(primary_tau): bool(step_success),\n",
    "        })\n",
    "        iou_list_best_per_gt.extend(matched_iou if matched_iou else [0.0])\n",
    "\n",
    "    # task completion = every step passed\n",
    "    task_completed = all(step_pass.values()) if len(step_pass) > 0 else False\n",
    "\n",
    "    # aggregate metrics over this task (across all GT boxes in task)\n",
    "    mIoU = sum(iou_list_best_per_gt) / max(1, len(iou_list_best_per_gt))\n",
    "    acc_at = {\n",
    "        \"Acc@{:.1f}\".format(t): sum(1 for v in iou_list_best_per_gt if v >= t) / max(1, len(iou_list_best_per_gt))\n",
    "        for t in thresholds\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"task\": os.path.basename(task_dir),\n",
    "        \"task_query\": task_query,\n",
    "        \"exists\": True,\n",
    "        \"task_completed@{:.2f}\".format(primary_tau): bool(task_completed),\n",
    "        \"num_images\": len(gt_by_img),\n",
    "        \"num_gt_boxes\": int(total_gt_boxes),\n",
    "        \"mIoU\": mIoU,\n",
    "        **acc_at,\n",
    "        \"per_image\": per_image_rows,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a7c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_task_dirs(root_dir: str) -> List[str]:\n",
    "    # A task dir has an annotations.json (ground truth)\n",
    "    out = []\n",
    "    for name in sorted(os.listdir(root_dir)):\n",
    "        task_dir = os.path.join(root_dir, name)\n",
    "        if not os.path.isdir(task_dir): \n",
    "            continue\n",
    "        if name.lower() == \"predictions-qwen2.5-vl\": \n",
    "            continue\n",
    "        if os.path.exists(os.path.join(task_dir, \"annotations.json\")):\n",
    "            out.append(task_dir)\n",
    "    return out\n",
    "\n",
    "def evaluate_all(root_dir: str, pred_dir: str,\n",
    "                 primary_tau: float, thresholds: List[float],\n",
    "                 require_label_match: bool = True):\n",
    "    tasks = list_task_dirs(root_dir)\n",
    "    print(f\"Found {len(tasks)} task(s) with annotations.\")\n",
    "\n",
    "    per_task_results = []\n",
    "    overall_iou_values = []\n",
    "    overall_gt_count = 0\n",
    "    completed = 0\n",
    "\n",
    "    for task_dir in tasks:\n",
    "        task_name = os.path.basename(task_dir)\n",
    "        pred_task_dir = os.path.join(pred_dir, task_name)\n",
    "        res = score_task(\n",
    "            task_dir, pred_task_dir,\n",
    "            primary_tau=primary_tau,\n",
    "            thresholds=thresholds,\n",
    "            require_label_match=require_label_match\n",
    "        )\n",
    "        per_task_results.append(res)\n",
    "\n",
    "        # accumulate for overall\n",
    "        if res.get(\"exists\"):\n",
    "            # collect per-image IoUs (all GTs)\n",
    "            for row in res.get(\"per_image\", []):\n",
    "                for v in row.get(\"ious_per_gt\", []):\n",
    "                    overall_iou_values.append(float(v))\n",
    "                    overall_gt_count += 1\n",
    "            if res.get(f\"task_completed@{primary_tau:.2f}\"):\n",
    "                completed += 1\n",
    "\n",
    "        # save per-task file\n",
    "        out_task_json = os.path.join(pred_dir, task_name, \"eval.json\")\n",
    "        with open(out_task_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(res, f, indent=2)\n",
    "        print(f\"  Saved per-task eval: {out_task_json}\")\n",
    "\n",
    "    # overall metrics\n",
    "    overall_mIoU = (sum(overall_iou_values) / overall_gt_count) if overall_gt_count else 0.0\n",
    "    overall_acc = {\n",
    "        f\"Acc@{t:.1f}\": (sum(1 for v in overall_iou_values if v >= t) / overall_gt_count) if overall_gt_count else 0.0\n",
    "        for t in thresholds\n",
    "    }\n",
    "    task_completion_rate = (completed / len(tasks)) if tasks else 0.0\n",
    "\n",
    "    overall = {\n",
    "        \"num_tasks\": len(tasks),\n",
    "        \"overall_num_gt_boxes\": int(overall_gt_count),\n",
    "        \"task_completion_rate@{:.3f}\".format(primary_tau): task_completion_rate,\n",
    "        \"overall_mIoU\": overall_mIoU,\n",
    "        **overall_acc,\n",
    "    }\n",
    "\n",
    "    # save summary\n",
    "    out_summary = os.path.join(pred_dir, \"_eval_summary.json\")\n",
    "    with open(out_summary, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"overall\": overall, \"per_task\": per_task_results}, f, indent=2)\n",
    "    print(\"\\n=== Overall Summary ===\")\n",
    "    for k, v in overall.items():\n",
    "        print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")\n",
    "    print(f\"\\nSaved: {out_summary}\")\n",
    "\n",
    "# Run it\n",
    "evaluate_all(\n",
    "    ROOT_DIR, PRED_DIR,\n",
    "    primary_tau=PRIMARY_TAU,\n",
    "    thresholds=THRESHOLDS,\n",
    "    require_label_match=REQUIRE_LABEL_MATCH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba0a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen3-vl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
